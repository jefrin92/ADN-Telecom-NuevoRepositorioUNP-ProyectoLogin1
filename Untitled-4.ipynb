{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "Importar las bibliotecas necesarias, incluyendo seaborn, pandas, numpy, sklearn y matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar y explorar el conjunto de datos\n",
    "Cargar el conjunto de datos 'Networks_Components.csv' y explorar su estructura y contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos\n",
    "df = pd.read_csv('Networks_Components.csv')\n",
    "\n",
    "# Mostrar las primeras 5 filas del conjunto de datos\n",
    "print(df.head())\n",
    "\n",
    "# Mostrar información general sobre el conjunto de datos\n",
    "print(df.info())\n",
    "\n",
    "# Mostrar estadísticas descriptivas del conjunto de datos\n",
    "print(df.describe())\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según el costo\n",
    "sns.histplot(data=df, x='costo', kde=True)\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según la velocidad de red\n",
    "sns.histplot(data=df, x='velocidad_de_red', kde=True)\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según el año\n",
    "sns.histplot(data=df, x='año', kde=True)\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según la estructura de la red\n",
    "sns.countplot(data=df, x='estructura_de_la_red')\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según el número de puertos\n",
    "sns.countplot(data=df, x='numero_de_puertos')\n",
    "\n",
    "# Mostrar la matriz de correlación de las características numéricas\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos\n",
    "Limpiar y preparar los datos para el análisis, incluyendo la gestión de valores perdidos y la codificación de variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "# Verificar si hay valores perdidos en el conjunto de datos\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Si hay valores perdidos, podemos optar por eliminar las filas con valores perdidos o llenarlas con un valor específico.\n",
    "# En este caso, vamos a llenar los valores perdidos con la mediana de la columna correspondiente.\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Verificar si se han gestionado correctamente los valores perdidos\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Codificar las variables categóricas\n",
    "# En este caso, vamos a codificar la variable 'estructura_de_la_red' usando la codificación de etiquetas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['estructura_de_la_red'] = le.fit_transform(df['estructura_de_la_red'])\n",
    "\n",
    "# Verificar si se ha realizado correctamente la codificación de las variables categóricas\n",
    "print(df.head())\n",
    "\n",
    "# Normalizar las características numéricas para que tengan una media de 0 y una desviación estándar de 1\n",
    "scaler = StandardScaler()\n",
    "df[['costo', 'velocidad_de_red', 'año', 'numero_de_puertos']] = scaler.fit_transform(df[['costo', 'velocidad_de_red', 'año', 'numero_de_puertos']])\n",
    "\n",
    "# Verificar si se ha realizado correctamente la normalización de las características numéricas\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio de datos\n",
    "Realizar un análisis exploratorio de los datos para entender las relaciones y patrones en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar un análisis exploratorio de los datos\n",
    "# Mostrar la distribución de los componentes de red según el costo\n",
    "sns.histplot(data=df, x='costo', kde=True)\n",
    "plt.title('Distribución de los componentes de red según el costo')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según la velocidad de red\n",
    "sns.histplot(data=df, x='velocidad_de_red', kde=True)\n",
    "plt.title('Distribución de los componentes de red según la velocidad de red')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según el año\n",
    "sns.histplot(data=df, x='año', kde=True)\n",
    "plt.title('Distribución de los componentes de red según el año')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según la estructura de la red\n",
    "sns.countplot(data=df, x='estructura_de_la_red')\n",
    "plt.title('Distribución de los componentes de red según la estructura de la red')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la distribución de los componentes de red según el número de puertos\n",
    "sns.countplot(data=df, x='numero_de_puertos')\n",
    "plt.title('Distribución de los componentes de red según el número de puertos')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la matriz de correlación de las características numéricas\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Matriz de correlación de las características numéricas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo de recomendación\n",
    "Entrenar un modelo de recomendación utilizando los datos preprocesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n",
    "X = df[['costo', 'velocidad_de_red', 'año', 'estructura_de_la_red', 'numero_de_puertos']]\n",
    "y = df['recomendacion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo de recomendación\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo de recomendación\n",
    "y_pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo\n",
    "Evaluar el rendimiento del modelo de recomendación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "# Crear una matriz de confusión para visualizar las predicciones del modelo\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.xlabel('Predicho')\n",
    "plt.ylabel('Verdadero')\n",
    "plt.show()\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(f'Precisión del modelo: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Realizar una validación cruzada para evaluar la eficacia del modelo\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(knn, X, y, cv=5)\n",
    "print(f'Puntuaciones de la validación cruzada: {scores}')\n",
    "print(f'Promedio de las puntuaciones de la validación cruzada: {scores.mean()}')\n",
    "\n",
    "# Realizar una búsqueda en cuadrícula para optimizar los parámetros del modelo\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors': np.arange(1, 50)}\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_gscv.fit(X, y)\n",
    "\n",
    "# Mostrar el mejor parámetro y la mejor puntuación después de la optimización\n",
    "print(f'Mejor parámetro: {knn_gscv.best_params_}')\n",
    "print(f'Mejor puntuación: {knn_gscv.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar recomendaciones\n",
    "Utilizar el modelo entrenado para generar recomendaciones de componentes de red basadas en ciertos patrones, como el costo, la velocidad de red, el año, la estructura de la red y el número de puertos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar recomendaciones\n",
    "# Definir los patrones para los que queremos generar recomendaciones\n",
    "patrones = {\n",
    "    'costo': 0.5,  # Normalizado\n",
    "    'velocidad_de_red': 0.7,  # Normalizado\n",
    "    'año': 0.6,  # Normalizado\n",
    "    'estructura_de_la_red': 1,  # Codificado\n",
    "    'numero_de_puertos': 0.8  # Normalizado\n",
    "}\n",
    "\n",
    "# Convertir los patrones en un DataFrame para poder usarlos en el modelo\n",
    "patrones_df = pd.DataFrame([patrones])\n",
    "\n",
    "# Usar el modelo para generar una recomendación basada en los patrones\n",
    "recomendacion = knn.predict(patrones_df)\n",
    "\n",
    "# Imprimir la recomendación\n",
    "print(f'Recomendación: {recomendacion[0]}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

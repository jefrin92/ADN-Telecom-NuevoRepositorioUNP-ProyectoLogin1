{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar las bibliotecas requeridas\n",
    "Importar las bibliotecas necesarias, incluyendo seaborn, pandas, numpy, sklearn y matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas requeridas\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y limpieza de datos\n",
    "Cargar los datos de los componentes de red y realizar la limpieza inicial de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "data = pd.read_csv('network_components.csv')\n",
    "\n",
    "# Verificar los primeros datos\n",
    "print(data.head())\n",
    "\n",
    "# Verificar si hay valores nulos\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Limpieza de datos: eliminar las filas con valores nulos\n",
    "data = data.dropna()\n",
    "\n",
    "# Verificar los datos después de la limpieza\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio de datos\n",
    "Realizar un análisis exploratorio de los datos para entender las características y relaciones de los componentes de red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis exploratorio de datos\n",
    "# Descripción general de los datos\n",
    "print(data.describe())\n",
    "\n",
    "# Visualización de la distribución de los datos\n",
    "sns.pairplot(data)\n",
    "\n",
    "# Correlación entre las características\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, annot=True)\n",
    "\n",
    "# Visualización de la relación entre el costo y la velocidad de la red\n",
    "sns.scatterplot(x='cost', y='network_speed', data=data)\n",
    "\n",
    "# Visualización de la relación entre el año y la velocidad de la red\n",
    "sns.scatterplot(x='year', y='network_speed', data=data)\n",
    "\n",
    "# Visualización de la relación entre la estructura de la red y la velocidad de la red\n",
    "sns.scatterplot(x='network_structure', y='network_speed', data=data)\n",
    "\n",
    "# Visualización de la relación entre el número de puertos y la velocidad de la red\n",
    "sns.scatterplot(x='number_of_ports', y='network_speed', data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos\n",
    "Preparar los datos para el entrenamiento del modelo, incluyendo la codificación de variables categóricas y la normalización de variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "data = pd.get_dummies(data, columns=['network_structure'], drop_first=True)\n",
    "\n",
    "# Normalización de variables numéricas\n",
    "scaler = StandardScaler()\n",
    "data[['cost', 'network_speed', 'year', 'number_of_ports']] = scaler.fit_transform(data[['cost', 'network_speed', 'year', 'number_of_ports']])\n",
    "\n",
    "# Verificar los datos después del preprocesamiento\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo de recomendación\n",
    "Entrenar un modelo de recomendación utilizando un algoritmo de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X = data.drop('network_speed', axis=1)\n",
    "y = data['network_speed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo de recomendación\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "\n",
    "# Visualizar la importancia de las características\n",
    "importance = model.feature_importances_\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo\n",
    "Evaluar el rendimiento del modelo de recomendación utilizando métricas apropiadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy * 100}%')\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Matriz de confusión')\n",
    "plt.xlabel('Clase predicha')\n",
    "plt.ylabel('Clase verdadera')\n",
    "plt.show()\n",
    "\n",
    "# Generar el informe de clasificación\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Informe de clasificación:')\n",
    "print(report)\n",
    "\n",
    "# Visualizar la importancia de las características\n",
    "importance = model.feature_importances_\n",
    "plt.bar(X.columns, importance)\n",
    "plt.title('Importancia de las características')\n",
    "plt.xlabel('Características')\n",
    "plt.ylabel('Importancia')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendación de componentes de red\n",
    "Utilizar el modelo entrenado para recomendar componentes de red basados en ciertos patrones, como el costo, la velocidad de red, el año, la estructura de la red y el número de puertos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomendación de componentes de red\n",
    "# Definir los patrones para la recomendación\n",
    "patterns = {\n",
    "    'cost': 0.5,  # Costo\n",
    "    'year': 2020,  # Año\n",
    "    'network_structure': 'Ethernet',  # Estructura de la red\n",
    "    'number_of_ports': 24  # Número de puertos\n",
    "}\n",
    "\n",
    "# Codificar y normalizar los patrones\n",
    "patterns_encoded = pd.get_dummies(pd.DataFrame([patterns]), columns=['network_structure'], drop_first=True)\n",
    "patterns_encoded[['cost', 'year', 'number_of_ports']] = scaler.transform(patterns_encoded[['cost', 'year', 'number_of_ports']])\n",
    "\n",
    "# Realizar la recomendación\n",
    "recommendation = model.predict(patterns_encoded)\n",
    "print(f'Recommended network speed: {recommendation[0]}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

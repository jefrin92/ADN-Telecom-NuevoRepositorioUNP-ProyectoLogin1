# -*- coding: utf-8 -*-
"""Datos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19fzOAcCMOmzDFDBSC3PAgMP4AIgcBRn9

# Importar las bibliotecas necesarias
Importar las bibliotecas necesarias para el análisis de datos, incluyendo pandas, numpy y sklearn.
"""

# Importar las bibliotecas necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
import json

"""# Cargar y explorar los datos
Cargar los datos del archivo Networks_Components.csv y realizar una exploración inicial de los datos.
"""

# Cargar los datos
df = pd.read_csv('Networks_Components.csv',sep=";")

# Mostrar las primeras 5 filas del DataFrame
print(df.head())

# Mostrar información general sobre los datos
print(df.info())

# Mostrar estadísticas descriptivas de los datos
print(df.describe())

# Verificar si hay valores nulos en los datos
print(df.isnull().sum())

"""# Preprocesamiento de los datos
Realizar el preprocesamiento de los datos, incluyendo la limpieza de datos, la codificación de variables categóricas y la normalización de variables numéricas.
"""

# Eliminar las filas con valores nulos
df = df.dropna()

# Codificar las variables categóricas
df = pd.get_dummies(df)

# Normalizar las variables numéricas
scaler = StandardScaler()
df[df.columns] = scaler.fit_transform(df[df.columns])

# Mostrar las primeras 5 filas del DataFrame después del preprocesamiento
print(df.head())

"""# Entrenamiento del modelo
Entrenar un modelo de aprendizaje automático para recomendar componentes de red basado en los datos preprocesados.
"""

# Asumir que la columna objetivo se llama 'COSTO'
target_column = 'COSTO'  # Actualiza esto con el nombre correcto

# Asegurarse de que la columna objetivo esté presente
if target_column in df.columns:
    # Verificar el tipo de datos de la columna objetivo
    print(df[target_column].dtype)

    # Si es continua, convertirla a categórica
    if df[target_column].dtype == 'float64' or df[target_column].dtype == 'int64':
        # Convertir a categórica dividiendo en bins (ejemplo)
        df[target_column] = pd.cut(df[target_column], bins=3, labels=["low", "medium", "high"])

    # Dividir los datos en conjuntos de entrenamiento y prueba
    X = df.drop(target_column, axis=1)
    y = df[target_column]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Entrenar el modelo KNN
    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(X_train, y_train)

    # Hacer predicciones con el modelo
    y_pred = knn.predict(X_test)

    # Evaluar el modelo
    score = knn.score(X_test, y_test)
    print(f'Accuracy: {score}')

    # Generar el reporte de clasificación
    results = classification_report(y_test, y_pred, output_dict=True)

    # Guardar los resultados en un archivo .json
    with open('results.json', 'w') as f:
        json.dump(results, f)
else:
    print(f"La columna '{target_column}' no se encuentra en el DataFrame")

"""# Evaluación del modelo
Evaluar el rendimiento del modelo utilizando métricas adecuadas.
"""

# Predicciones del modelo
y_pred = knn.predict(X_test)

# Evaluación del modelo
print("Matriz de confusión:")
print(confusion_matrix(y_test, y_pred))

print("\nInforme de clasificación:")
print(classification_report(y_test, y_pred))

# Guardar los resultados en un archivo .json
results = {
    "confusion_matrix": confusion_matrix(y_test, y_pred).tolist(),
    "classification_report": classification_report(y_test, y_pred, output_dict=True)
}

with open('results.json', 'w') as f:
    json.dump(results, f)

print("\nResultados guardados en results.json")

"""# Recomendación de componentes de red
Utilizar el modelo entrenado para recomendar componentes de red.
"""

# Cargar los resultados del modelo desde el archivo JSON
with open('results.json', 'r') as f:
    results = json.load(f)

# Verificar la estructura de los resultados
if "confusion_matrix" in results and "classification_report" in results:
    # Imprimir los resultados
    print("\nMatriz de confusión:")
    print(np.array(results["confusion_matrix"]))

    print("\nInforme de clasificación:")
    for class_name, metrics in results["classification_report"].items():
        if isinstance(metrics, dict):
            print(f"\nClase: {class_name}")
            for metric_name, metric_value in metrics.items():
                print(f"{metric_name}: {metric_value}")
        else:
            print(f"\nClase: {class_name}")
            print(f"{metrics}")

    # Recomendar un componente de red basado en los resultados
    # Aquí, simplemente recomendamos el componente con la mayor precisión
    best_component = max(results["classification_report"], key=lambda x: results["classification_report"][x]["precision"] if isinstance(results["classification_report"][x], dict) else 0)
    print(f"\nEl componente de red recomendado es: {best_component}")
else:
    print("Los resultados cargados no contienen la matriz de confusión o el informe de clasificación")

"""
mapa

"""

# Graficar los resultados
plt.figure(figsize=(10, 6))
plt.plot(y_test.values, color='blue', label='Real')
plt.plot(y_pred, color='red', label='Predicted')
plt.title('Network Component Recommendation')
plt.xlabel('Número de Componentes')
plt.ylabel('Categoría')
plt.legend()
# Guardar el gráfico en un archivo de imagen
plt.savefig('grafico2.png')
# Mostrar el gráfico
plt.show()

# Generar un gráfico
plt.figure(figsize=(10, 6))
plt.plot(y_test, color='blue', label='Real')
plt.plot(y_pred, color='red', label='Predicted')
plt.title('Network Component Recommendation')
plt.xlabel('Number of Components')
plt.ylabel('Cost')
plt.legend()

# Guardar el gráfico en un archivo de imagen
plt.savefig('grafico.png')

# Mostrar el gráfico
plt.show()

# Convertir la matriz de confusión a un array de numpy
confusion_matrix = np.array(results["confusion_matrix"])

# Crear un heatmap con seaborn
plt.figure(figsize=(10, 7))
sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')

# Agregar títulos y etiquetas
plt.title('Matriz de Confusión')
plt.xlabel('Clase Predicha')
plt.ylabel('Clase Verdadera')

# Mostrar el gráfico
plt.show()

# Extraer las precisiones de cada componente
components = []
precisions = []

for class_name, metrics in results["classification_report"].items():
    if isinstance(metrics, dict) and "precision" in metrics:
        components.append(class_name)
        precisions.append(metrics["precision"])

# Crear un gráfico de barras
plt.figure(figsize=(10, 6))
plt.bar(components, precisions, color='blue')

# Agregar títulos y etiquetas
plt.title('Precisión por Componente')
plt.xlabel('Componente')
plt.ylabel('Precisión')
# Guardar el gráfico en formato PDF
plt.savefig('barras.png')
# Mostrar el gráfico
plt.show()

"""# Guardar los resultados en un archivo .json
Guardar los resultados de la recomendación en un archivo .json.
"""

# Importar la biblioteca para manejar archivos JSON
import json

# Crear un diccionario para almacenar los resultados
results = {
    "confusion_matrix": confusion_matrix(y_test, y_pred).tolist(),
    "classification_report": classification_report(y_test, y_pred, output_dict=True)
}

# Guardar los resultados en un archivo .json
with open('results.json', 'w') as f:
    json.dump(results, f)

print("Resultados guardados en results.json")